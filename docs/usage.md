# Usage Guide

## Command Line Interface

The `tem-seg` command-line tool provides several commands for working with TEM images:

```bash
tem-seg --help
```

### Training

The training process includes:
- K-fold cross-validation (when total-folds > 1)
- Automatic model checkpointing for best validation performance
- Evaluation metrics including F1 and F2 scores
- JSON logging of training history and evaluation results

To train a U-Net model for semantic segmentation:

```bash
tem-seg train \
    dataset_name \
    --organelle mitochondria \
    --fold-n 1 \
    --total-folds 5 \
    --shuffle-training \
    --batch-size 16 \
    --n-epochs-per-run 1200
```

#### Parameters

The training process can be customized with the following parameters:

- `dataset_name`: Name of the dataset to train on (corresponds to directory in `data/`)
- `fold_n`: Current fold number to train for k-fold cross-validation
- `total_folds`: Total number of folds for cross-validation
- `shuffle_training`: Whether to shuffle the training data
- `batch_size`: Batch size for training
- `n_epochs_per_run`: Number of epochs per training run


The output files will have the following structure:


For single-fold training:
```
models/unet/dataset_name/
└── single_fold/
    └── mitochondria/
        └── kf01/
            ├── ckpt/
            │   └── last.keras
            ├── evaluation/
            │   ├── nnnnn_evaluation.json
            │   └── ...
            └── logs/
                ├── metrics.tsv
                └── train/
                    ├── events.out.tfevents.*.v2
```

For k-fold cross-validation:
```
models/unet/dataset_name/
└── 5-fold_cross_validation/
    └── mitochondria/
        ├── kf01/
        │   ├── ckpt/
        │   │   ├── best_loss/
        │   │   │   └── best_logs.json
        │   │   ├── best_loss.keras
        │   │   └── last.keras
        │   ├── evaluation/
        │   │   ├── nnnnn_evaluation.json
        │   │   └── ...
        │   └── logs/
        │       ├── metrics.tsv
        │       ├── train/
        │       │   └── events.out.tfevents.*.v2
        │       └── validation/
        │           └── events.out.tfevents.*.v2
        ├── kf02/
        │   ├── ckpt/
        │   │   ├── best_loss/
        │   │   │   └── best_logs.json
        │   │   ├── best_loss.keras
        │   │   └── last.keras
        │   └── ...
        └── kf03/
            └── ...
```

### Prediction

To generate predictions using a trained model:

```bash
tem-seg predict \
    /path/to/images/*.tif \
    --model-architecture unet \
    --model-name Mixture \
    --organelle mitochondria \
    --use-ensemble \
    --cross-validation-kfolds 5 \
    --checkpoint last
```

#### Parameters

- `filepaths` (positional): Paths or glob(s) to input images.
- `--model-architecture, -a` (str, default: `unet`): Architecture to use.
- `--model-name, -n` (str, default: `Mixture`): Model/version name.
- `--organelle, -o` (str, default: `mitochondria`): Target organelle.
- `--force-prediction, -f` (flag, default: false): Overwrite if outputs exist.
- `--models-folder, -m` (path, optional): Directory containing models to use.
- `--use-ensemble, -e` (flag, default: false): Use ensemble model.
- `--checkpoint, -c` (str, default: `last`): Checkpoint to load.
- `--cross-validation-kfolds, -k` (int, optional): Number of k-folds to aggregate.
- `--round-output, -r` (flag, default: false): Round predictions to nearest integer.
- `--pixel-size-nm, -p` (float, optional): Calibrated pixel size (nm/pixel) to bypass automatic detection.
- `--pixel-sizes-filepath, -P` (path, optional): CSV/TSV/XLSX with `filename` and pixel size (nm/pixel).

The output structure will be:

```
path/to/images/
└── prediction/
    └── Mixture_k5/
        └── mitochondria/
            ├── image1-mitochondria.png
            ├── image2-mitochondria.png
            └── ...
├── image1.tif
├── image2.tif
└── ...
```

### Analysis

The analysis workflow processes images in a study directory structure. A study typically contains multiple conditions (e.g., control, treatment), each with its own set of TEM images.

To analyze predictions:

```bash
tem-seg analyze study_name \
  --model-name Mixture \
  --organelle mitochondria \
  --n-jobs 4  # Optional: use multiple CPU cores
```

This will:
1. Find all TEM images in the study directory
2. Load prediction images generated by the `predict` command
3. Create softened versions of the predictions if needed
4. Analyze the morphology of the detected organelles
5. Save the results in JSON, GeoJSON, and CSV formats for each image

#### Analysis Output Files

For each image, the analysis generates several output files:

- `{image}-{organelle}.json`: Contains detailed measurements for each detected organelle instance
- `{image}-{organelle}.csv`: Same data as the JSON file but in CSV format for easier data analysis
- `{image}-{organelle}.geojson`: Contains geometric information about each organelle for visualization
- `{image}-{organelle}-soft.png`: A softened version of the prediction used for analysis

#### Morphological Measurements

The analysis includes the following morphological measurements for each organelle:

- Area (μm²)
- Thickness (μm)
- Extended length (μm)
- Arc length (μm)
- Min/max/mean caliper diameter (μm)
- Center coordinates

### Consolidating Results

After running analysis on a study, you can consolidate all the individual CSV files into a single file:

```bash
tem-seg consolidate study_name \
  --model-name Mixture \
  --organelle mitochondria \
  --output-file results/my_consolidated_results.csv
```

If no output file is specified, the results will be saved to `results/{study_name}_{model_name}_{organelle}_consolidated.csv`.

## Study Directory Structure

The analysis workflow expects a specific directory structure:

```
studies/
└── study_name/
    ├── condition1/
    │   ├── image1.tif
    │   ├── image2.tif
    │   └── prediction/
    │       └── Mixture/
    │           └── mitochondria/
    │               ├── image1-mitochondria.png
    │               ├── image1-mitochondria-soft.png
    │               ├── image1-mitochondria.json
    │               ├── image1-mitochondria.csv
    │               ├── image1-mitochondria.geojson
    │               └── ...
    └── condition2/
        ├── image1.tif
        ├── image2.tif
        └── ...
```

The analysis command will process all images in each condition directory and save the results in the corresponding `prediction/{model_name}/{organelle}/` directory.
